{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SODA encoder\n",
    "\n",
    "Code for training our implementation of [SODA](https://arxiv.org/abs/2311.17901) encoder on a variation of the [Deepmind's 3D-Shapes Dataset](https://github.com/google-deepmind/3d-shapes).\n",
    "\n",
    "First, as the authors mention in the paper, the latent representation of the image is derived by a [ResNet](https://arxiv.org/pdf/1512.03385) encoder (Hudson, et al., 2023). in this case we are going to train a **ResNet18 to predict the latent representations of the images dataset**. Our implementation of ResNet is based in the [Pytorch Resnet Module Source Code](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py). So we are not using any of the pretrained ResNet models from PuTorch."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
